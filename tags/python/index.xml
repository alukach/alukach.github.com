<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>python on anthony lukach</title><link>https://alukach.com/tags/python/</link><description>Recent content in python on anthony lukach</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Anthony Lukach</copyright><lastBuildDate>Fri, 02 Oct 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://alukach.com/tags/python/index.xml" rel="self" type="application/rss+xml"/><item><title>Using CloudFront as a Reverse Proxy</title><link>https://alukach.com/posts/using_cloudfont_as_a_reverse_proxy/</link><pubDate>Fri, 02 Oct 2020 00:00:00 +0000</pubDate><guid>https://alukach.com/posts/using_cloudfont_as_a_reverse_proxy/</guid><description>Alternate title: How to be master of your domain.
The basic idea of this ticket is to demonstrate how CloudFront can be utilized as a serverless reverse-proxy, allowing you to host all of your application&amp;rsquo;s content and services from a single domain. This minimizes a project&amp;rsquo;s TLD footprint while providing project organization and performance along the way.
Why Within the large organizations, it can be a pain to get a subdomain for a project.</description></item><item><title>How to generate a database URI from an AWS Secret</title><link>https://alukach.com/posts/database_uri_from_secret/</link><pubDate>Mon, 15 Jun 2020 00:00:00 +0000</pubDate><guid>https://alukach.com/posts/database_uri_from_secret/</guid><description>A quick note about how to generate a database URI (or any other derived string) from an AWS SecretsManager SecretTargetAttachment (such as what&amp;rsquo;s provided via a RDS DatabaseInstance&amp;rsquo;s secret property).
1 2 3 4 5 6 7 8 9 10 11 db = rds.DatabaseInstance( # ... ) db_val = lambda field: db.secret.secret_value_from_json(field).to_string() task_definition.add_container( environment=dict( # ... PGRST_DB_URI=f&amp;#34;postgres://{db_val(&amp;#39;username&amp;#39;)}:{db_val(&amp;#39;password&amp;#39;)}@{db_val(&amp;#39;host&amp;#39;)}:{db_val(&amp;#39;port&amp;#39;)}/&amp;#34;, ), # ... )</description></item><item><title>Tips for working with a large number of files in S3</title><link>https://alukach.com/posts/tips_for_working_with_a_large_number_of_files_in_s3/</link><pubDate>Sat, 30 May 2020 00:00:00 +0000</pubDate><guid>https://alukach.com/posts/tips_for_working_with_a_large_number_of_files_in_s3/</guid><description>I would argue that S3 is basically AWS' best service. It&amp;rsquo;s super cheap, it&amp;rsquo;s basically infinitely scalable, and it never goes down (except for when it does). Part of its beauty is its simplicity. You give it a file and a key to identify that file, you can have faith that it will store it without issue. You give it a key, you can have faith that it will return the file represented by that key, assuming there is one.</description></item><item><title>Boilerplate for S3 Batch Operation Lambda</title><link>https://alukach.com/posts/aws-s3-batch-operation-lambda-boilerplate/</link><pubDate>Fri, 20 Dec 2019 00:00:00 +0000</pubDate><guid>https://alukach.com/posts/aws-s3-batch-operation-lambda-boilerplate/</guid><description>S3 Batch Operation provide a simple way to process a number of files stored in an S3 bucket with a Lambda function. However, the Lambda function must return particular Response Codes. Below is an example of a Lambda function written in Python that works with AWS S3 Batch Operations.</description></item><item><title>Parsing S3 Inventory CSV output in Python</title><link>https://alukach.com/posts/parsing-s3-inventory-output/</link><pubDate>Mon, 16 Dec 2019 00:00:00 +0000</pubDate><guid>https://alukach.com/posts/parsing-s3-inventory-output/</guid><description>S3 Inventory is a great way to access a large number of keys in an S3 Bucket. Its output is easily parsed by AWS Athena, enabling queries across the key names (e.g. find all keys ending with .png)
However, sometimes you just need to list all of the keys mentioned in the S3 Inventory output (e.g. populating an SQS queue with every keyname mentioned in an inventory output). The following code is an example of doing such task in Python:</description></item><item><title>A PIL-friendly class for S3 objects</title><link>https://alukach.com/posts/pil_friendly_s3_file/</link><pubDate>Wed, 11 Dec 2019 00:00:00 +0000</pubDate><guid>https://alukach.com/posts/pil_friendly_s3_file/</guid><description>Here&amp;rsquo;s a quick example of creating an file-like object in Python that represents an object on S3 and plays nicely with PIL. This ended up being overkill for my needs but I figured somebody might get some use out of it.</description></item><item><title>Natural Language Toolkit Notes</title><link>https://alukach.com/posts/nltk-notes/</link><pubDate>Sun, 25 Aug 2013 00:00:00 +0000</pubDate><guid>https://alukach.com/posts/nltk-notes/</guid><description>I&amp;rsquo;ve been experimenting with Python&amp;rsquo;s Natural Language Toolkit, following along with Steven Bird, Ewan Klein, and Edward Loper&amp;rsquo;s book &amp;ldquo;Natural Language Processing with Python &amp;mdash; Analyzing Text with the Natural Language Toolkit&amp;rdquo; (pdf version).
So far, the book&amp;rsquo;s been great. As I&amp;rsquo;m going through the book, I&amp;rsquo;ve been writing down notes relating to the book&amp;rsquo;s examples. I&amp;rsquo;ve made a Github repo to store these notes and experiments that I may be doing using the NLTK here.</description></item></channel></rss>